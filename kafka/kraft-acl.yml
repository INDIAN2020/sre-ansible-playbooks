---
- name: Setup Kafka KRaft cluster with ACLs
  hosts: kafka_servers
  become: true
  vars:
    kafka_version: "3.0.0"
    kafka_home: "/opt/kafka"
    kafka_download_url: "https://downloads.apache.org/kafka/{{ kafka_version }}/kafka_2.13-{{ kafka_version }}.tgz"
    data_dir: "/var/lib/kafka"
    log_dir: "/var/log/kafka"
    config_file: "{{ kafka_home }}/config/kraft/server.properties"
    user: "kafka"
    group: "kafka"
  tasks:
    - name: Install required packages
      apt:
        name: "{{ item }}"
        state: present
      with_items:
        - wget
        - tar
        - openjdk-11-jdk

    - name: Create Kafka user
      user:
        name: "{{ user }}"
        group: "{{ group }}"
        createhome: no
        shell: /bin/false

    - name: Download Kafka
      get_url:
        url: "{{ kafka_download_url }}"
        dest: "/tmp/kafka.tgz"
      register: download_result

    - name: Extract Kafka
      unarchive:
        src: "/tmp/kafka.tgz"
        dest: "/opt"
        remote_src: yes
        creates: "/opt/kafka_2.13-{{ kafka_version }}"
      when: download_result.changed

    - name: Symlink Kafka directory
      file:
        src: "/opt/kafka_2.13-{{ kafka_version }}"
        dest: "{{ kafka_home }}"
        state: link
        force: yes

    - name: Ensure Kafka directories are owned by Kafka user
      file:
        path: "{{ item }}"
        state: directory
        owner: "{{ user }}"
        group: "{{ group }}"
        mode: '0755'
      with_items:
        - "{{ kafka_home }}"
        - "{{ data_dir }}"
        - "{{ log_dir }}"

    - name: Ensure Kafka config directory exists
      file:
        path: "{{ kafka_home }}/config/kraft"
        state: directory
        owner: "{{ user }}"
        group: "{{ group }}"
        mode: '0755'

    - name: Configure Kafka KRaft mode
      blockinfile:
        path: "{{ config_file }}"
        create: yes
        block: |
          node.id={{ item.index }}
          process.roles=broker,controller
          controller.quorum.voters=0@server1:9093,1@server2:9093,2@server3:9093
          listeners=PLAINTEXT://:9092,CONTROLLER://:9093
          listener.security.protocol.map=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
          inter.broker.listener.name=PLAINTEXT
          log.dirs={{ data_dir }}
          num.network.threads=3
          num.io.threads=8
          socket.send.buffer.bytes=102400
          socket.receive.buffer.bytes=102400
          socket.request.max.bytes=104857600
          log.retention.hours=168
          log.segment.bytes=1073741824
          log.retention.check.interval.ms=300000
      with_indexed_items: "{{ groups['kafka_servers'] }}"
      notify:
        - Restart Kafka

    - name: Setup Kafka systemd service
      copy:
        dest: /etc/systemd/system/kafka.service
        content: |
          [Unit]
          Description=Apache Kafka
          After=network.target

          [Service]
          User={{ user }}
          Group={{ group }}
          ExecStart={{ kafka_home }}/bin/kafka-server-start.sh {{ config_file }}
          ExecStop={{ kafka_home }}/bin/kafka-server-stop.sh
          Restart=on-failure

          [Install]
          WantedBy=multi-user.target
      notify:
        - Reload systemd

    - name: Start Kafka service
      systemd:
        name: kafka
        state: started
        enabled: yes
      when: false  # We use handler to start Kafka

    - name: Setup Kafka ACLs for topics
      command: "{{ kafka_home }}/bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:* --operation All --topic '*'"
      become_user: "{{ user }}"
      changed_when: false

    - name: Setup Kafka ACLs for consumer groups
      command: "{{ kafka_home }}/bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:* --operation All --group '*'"
      become_user: "{{ user }}"
      changed_when: false

  handlers:
    - name: Restart Kafka
      systemd:
        name: kafka
        state: restarted
        enabled: yes

    - name: Reload systemd
      systemd:
        daemon_reload: yes

  post_tasks:
    - name: Assert Kafka is running
      assert:
        that:
          - "ansible_facts.services['kafka'].state == 'running'"
